{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8be54d-da99-4fbc-95a1-74aa604e9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f62f353d-0b9e-4991-a05f-f543784d7544",
   "metadata": {},
   "source": [
    "This notebook builds a simple user-based collaborative filtering recommender system. The goal is to predict how a user might rate an anime they haven't seen yet, based on the ratings of other users with similar tastes. We will use two datasets: one containing user ratings and another containing anime titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0244eec-56ac-481f-b6bb-a73cdeca72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"rating.csv\",header=0)\n",
    "df=df[:int(len(df)*0.2)]\n",
    "df[\"rating\"]=df[\"rating\"].replace(-1,0)\n",
    "names_df=pd.read_csv(\"anime.csv\",header=0)\n",
    "names_df=pd.Series(names_df[\"name\"].values,index=names_df[\"anime_id\"].values)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "144b905d-6161-4899-ac98-9c4e2f94a006",
   "metadata": {},
   "source": [
    "First, we load the necessary libraries and datasets. We'll use pandas to handle our data. We read the rating.csv file, and to keep computation manageable, we'll work with a 20% sample of the data. We also preprocess the rating column by replacing -1 values ,{which often signify \"watched but not rated\"} with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec70d96c-99ca-4666-a28e-5658c305a1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 9159\n"
     ]
    }
   ],
   "source": [
    "df_pivot=pd.pivot_table(df,values=\"rating\",index=\"user_id\",columns=\"anime_id\",aggfunc=\"mean\",fill_value=0)[:100]\n",
    "#print(df_pivot)\n",
    "print(len(df_pivot),len(df_pivot.columns))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a548ca8d-2cdd-4250-86b4-066b00868b41",
   "metadata": {},
   "source": [
    "The core of collaborative filtering is the user-item matrix. We use pandas' pivot_table function to transform our ratings data into this format. In this matrix:\n",
    "\n",
    "Each row represents a unique user_id.\n",
    "\n",
    "Each column represents a unique anime_id.\n",
    "\n",
    "The value in each cell is the rating the user gave to that anime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eee4f0f-e96b-411f-a056-c03d3a581df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_similarity_score(df_pivot,user1,user2):\n",
    "    a1=df_pivot.loc[user1]\n",
    "    a2=df_pivot.loc[user2]\n",
    "    \n",
    "    a3=a1*a2\n",
    "    #print(a1.iloc[:10])\n",
    "    #print(a2.iloc[:10])\n",
    "    dot=sum(a3)\n",
    "    denominator=(sum(a1**2)*sum(a2**2))**0.5\n",
    "    if denominator==0:\n",
    "        return 0\n",
    "    return dot/denominator\n",
    "\n",
    "def make_user_similarity_matrix(df_pivot):\n",
    "    new_df=pd.DataFrame(0.0,columns=df_pivot.index,index=df_pivot.index)\n",
    "    users=list(df_pivot.index.values)\n",
    "    #print(len(users))\n",
    "    for user1 in users:\n",
    "        for user2 in users:\n",
    "            new_df.loc[user1,user2]=give_similarity_score(df_pivot,user1,user2)\n",
    "    \n",
    "    return new_df\n",
    "            \n",
    "\n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "503b1abe-2d8e-4dda-8dca-dcf880b13bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=make_user_similarity_matrix(df_pivot)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "df034399-b4b2-4970-89f5-04f85dd9b754",
   "metadata": {},
   "source": [
    "Now that we have the user-item matrix, we need to determine how similar users are to one another. We will use cosine similarity for this, which measures the cosine of the angle between two user-rating vectors. A score closer to 1 means the users have very similar tastes.\n",
    "The give_similarity_score function calculates this score between two users, and the make_user_similarity_matrix function iterates through all pairs of users to build a complete similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817881bf-cdcb-42c0-98ff-284d0da90bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_score_for_anime(df_similarity_matrix,df_pivot,user_id,anime_id):\n",
    "    ratings=df_pivot[anime_id]\n",
    "    scores=df_similarity_matrix[user_id]\n",
    "\n",
    "    numerator=sum(ratings*scores)-(df_pivot[anime_id][user_id]*df_similarity_matrix[user_id][user_id])\n",
    "    denominator=sum(scores)-df_similarity_matrix[user_id][user_id]\n",
    "    return numerator/denominator\n",
    "\n",
    "def give_score_for_every_anime(df_similarity_matrix,df_pivot,user_id):\n",
    "    anime_ids=list(df_pivot.columns)\n",
    "\n",
    "    values=[]\n",
    "    indexes=[]\n",
    "    for anime_id in anime_ids:\n",
    "        try:\n",
    "            indexes.append(names_df.loc[anime_id])\n",
    "            values.append(give_score_for_anime(df_similarity_matrix,df_pivot,user_id,anime_id))\n",
    "        except:\n",
    "            pass\n",
    "    return pd.Series(values,index=indexes)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "04df8d8a-389f-47c0-ae52-ba973bae29d6",
   "metadata": {},
   "source": [
    "The function give_score_for_anime calculates a single predicted score. It iterates through all other users, multiplies their rating for the anime by their similarity score to the target user, and sums the results. The give_score_for_every_anime function then uses this to generate a full list of predicted scores for a specific user across all animes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987d6ad1-a788-48cd-8240-ef332f47e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=give_score_for_every_anime(m,df_pivot,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4124691d-38b1-470d-85e3-753f4e5255cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sword Art Online                                    7.974732\n",
       "Death Note                                          4.892098\n",
       "Shingeki no Kyojin                                  4.284152\n",
       "Angel Beats!                                        4.062961\n",
       "Highschool of the Dead                              3.856566\n",
       "                                                      ...   \n",
       "Hatsune Miku: Hiyashite Narasou Okashi no Ii Oto    0.000000\n",
       "Gakuen Handsome: Legend of Sexy                     0.000000\n",
       "Gakuen Handsome: Haitoku no Lesson                  0.000000\n",
       "Trigger-chan                                        0.000000\n",
       "Garo: Guren no Tsuki Special                        0.000000\n",
       "Length: 9158, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693ea0b-4850-453e-bbde-2c44c84a4dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
